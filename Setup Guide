# Install AWS CLI
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# Install Terraform
wget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip
unzip terraform_1.6.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/

# Install kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Install Docker
sudo apt-get update
sudo apt-get install docker.io -y
sudo usermod -aG docker $USER

# Install eksctl
curl --silent --location "https://github.com/weksctl-io/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin



# Configure AWS credentials
aws configure
# Enter: Access Key ID, Secret Access Key, Region (us-east-1), Output (json)

# Set up billing alerts IMMEDIATELY
aws cloudwatch put-metric-alarm \
  --alarm-name billing-alert-50 \
  --alarm-description "Alert when bill exceeds $50" \
  --metric-name EstimatedCharges \
  --namespace AWS/Billing \
  --statistic Maximum \
  --period 21600 \
  --evaluation-periods 1 \
  --threshold 50 \
  --comparison-operator GreaterThanThreshold




# Create S3 bucket for Terraform state
aws s3api create-bucket \
  --bucket cloudops-terraform-state \
  --region us-east-1

# Enable versioning
aws s3api put-bucket-versioning \
  --bucket cloudops-terraform-state \
  --versioning-configuration Status=Enabled

# Create DynamoDB table for state locking
aws dynamodb create-table \
  --table-name terraform-state-lock \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST



# Clone your repository
git clone https://github.com/yourusername/cloudops-platform.git
cd cloudops-platform/terraform

# Initialize Terraform
terraform init

# Create terraform.tfvars
cat > terraform.tfvars <<EOF
aws_region = "us-east-1"
environment = "dev"
vpc_cidr = "10.0.0.0/16"
db_username = "dbadmin"
db_password = "CHANGE_ME_STRONG_PASSWORD"
EOF

# Plan and apply
terraform plan -out=tfplan
terraform apply tfplan


# Update kubeconfig
aws eks update-kubeconfig --name dev-eks-cluster --region us-east-1

# Verify connection
kubectl get nodes
kubectl get namespaces



-- Connect to RDS PostgreSQL
psql -h <rds-endpoint> -U dbadmin -d shopcloud

-- Users table
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password VARCHAR(255) NOT NULL,
    name VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Products table
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    price DECIMAL(10, 2) NOT NULL,
    category VARCHAR(100),
    stock INTEGER DEFAULT 0,
    image_url VARCHAR(500),
    active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Orders table
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    total_amount DECIMAL(10, 2) NOT NULL,
    status VARCHAR(50) DEFAULT 'PENDING',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Order items table
CREATE TABLE order_items (
    id SERIAL PRIMARY KEY,
    order_id INTEGER REFERENCES orders(id),
    product_id INTEGER REFERENCES products(id),
    quantity INTEGER NOT NULL,
    price DECIMAL(10, 2) NOT NULL
);

-- Indexes for performance
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_products_category ON products(category);
CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);



# Navigate to each service directory
cd services/user-service

# Build Docker image
docker build -t user-service:latest .

# Tag for ECR
docker tag user-service:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/user-service:latest

# Login to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com

# Push to ECR
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/user-service:latest

# Repeat for all services: product-service, cart-service, order-service



# Create secrets
kubectl create secret generic database-secrets \
  --from-literal=host=<rds-endpoint> \
  --from-literal=username=dbadmin \
  --from-literal=password=<your-password>

kubectl create secret generic app-secrets \
  --from-literal=jwt-secret=$(openssl rand -base64 32)

# Deploy services
kubectl apply -f k8s/user-service/
kubectl apply -f k8s/product-service/
kubectl apply -f k8s/cart-service/
kubectl apply -f k8s/order-service/

# Check deployments
kubectl get pods
kubectl get services



# Add secrets to GitHub repository
# Go to: Settings -> Secrets and variables -> Actions

# Required secrets:
AWS_ACCESS_KEY_ID=<your-access-key>
AWS_SECRET_ACCESS_KEY=<your-secret-key>
AWS_ACCOUNT_ID=<your-account-id>
SLACK_WEBHOOK_URL=<optional-slack-webhook>



# Make a change to a service
cd services/user-service
echo "// Updated" >> src/index.js

# Commit and push
git add .
git commit -m "Test CI/CD pipeline"
git push origin main

# Monitor in GitHub Actions tab
# Pipeline will: lint -> test -> build -> push -> deploy


# Create Kinesis stream
aws kinesis create-stream \
  --stream-name shopcloud-events \
  --shard-count 1

# Create Firehose delivery stream to S3
aws firehose create-delivery-stream \
  --delivery-stream-name shopcloud-to-s3 \
  --delivery-stream-type KinesisStreamAsSource \
  --kinesis-stream-source-configuration \
    KinesisStreamARN=<kinesis-arn>,RoleARN=<firehose-role-arn> \
  --s3-destination-configuration \
    BucketARN=arn:aws:s3:::shopcloud-analytics,Prefix=events/



-- Create Athena database
CREATE DATABASE shopcloud_analytics;

-- Create external table
CREATE EXTERNAL TABLE shopcloud_analytics.events (
    event_type STRING,
    order_id STRING,
    user_id STRING,
    total_amount DOUBLE,
    timestamp STRING
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION 's3://shopcloud-analytics/events/';

-- Query example
SELECT 
    DATE(timestamp) as date,
    COUNT(*) as order_count,
    SUM(total_amount) as total_revenue
FROM shopcloud_analytics.events
WHERE event_type = 'order_created'
GROUP BY DATE(timestamp)
ORDER BY date DESC;



# Add Helm repos
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# Install Prometheus
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace

# Get Grafana password
kubectl get secret --namespace monitoring prometheus-grafana \
  -o jsonpath="{.data.admin-password}" | base64 --decode

# Port forward to access Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Access: http://localhost:3000 (admin / <password>)



 Security Best Practices
       IAM Least Privilege

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject"
      ],
      "Resource": "arn:aws:s3:::shopcloud-data/*"
    }
  ]
}



# RDS encryption (in Terraform)
# storage_encrypted = true

# S3 encryption
aws s3api put-bucket-encryption \
  --bucket shopcloud-data \
  --server-side-encryption-configuration \
    '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'






